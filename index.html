
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Yuhao (Henry) Zhou</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="67%" valign="middle">
          <p align="center">
            <name>Yuhao (Henry) Zhou</name>
          </p>
          <p>
            I am currently a fourth-year computer engineering student at 
            <a href="https://www.utoronto.ca/">
            University of Toronto. 
            </a>
            My focus of study are machine learning, software engineering and system control.
            Since January in 2017, I have been working as an undergraduate research assistant under the supervision of 
            <a href="http://www.cs.utoronto.ca/~fidler/index.html"> Prof. Sanja Fidler </a> and 
            <a href="https://jimmylba.github.io/"> Prof. Jimmy Ba </a>
            on computer vison and reinforcement learning projects.
          </p>
          <p>
            Before I worked as a research assistant, I primarily spent my time on various software engineering internships.
            During which period, I gained strong coding skills through in-depth experience on large-scale engineering projects. 
          </p>
          
          </td>
          <td width="33%">
            <img src="images/profile_pic.jpg" width="200">
          </td>



        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="33%">
            <p align=center>
              Address: <br>
              RM1801, 24 Wellesley St. West <br>
              Toronto, Canada. M4Y 2X6
            </p>
          </td>
          <td width="33%">
            <p align=center>
              Email: <br>
              henryzhou-at-cs-dot-toronto-dot-edu <br>
              henry-dot-zhou-at-mail-dot-utoronto-dot-ca
            </p>
          </td>
          
        </tr>
        <tr>
          <p align=center>
          <a href="docs/cv.pdf">CV</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/yuhao-henry-zhou-3b0747a8/"> LinkedIn </a> &nbsp/&nbsp
          <a href="https://github.com/HenryZhou7">GitHub</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?hl=en&view_op=list_works&gmla=AJsN-F4R4Qg-wL0Q0FEVJvWi1iSUfsiFNIleGJMpOu9yonslcsFONDzWjjCMNb0bhtFo6FEdzReJjEHCGZoplRA9d5f8In1uLA&user=9-6xvKYAAAAJ">Google Scholar</a>
        </p>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Education</heading>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="images/education/uoft.png" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <a href="https://www.utoronto.ca/"><strong>University of Toronto</strong></a><br>
              <a href="https://www.ece.utoronto.ca/">Faculty of Applied Science and Engineering</a><br>
              Bachelor of Applied Science <br> 
              Specialist in Electrical and Computer Engineering<br>
              <em>with</em> Robotics and Mechatronics Minor <br>
              <em>Expected Graduation: May, 2019</em><br>

              <br>
              <em>Cumulative GPA</em>: 3.91 / 4.00
            </p>
            

          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Research</heading>
            <p>
              I am broadly interested in machine learning, computer vision, reinforcement learning, mathematics, image processing, and control theory.
            </p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

        <tr bgcolor="#ffffff">
          <td width="25%">
            <img src="images/research/movie4d.jpg" width='250'></div>   
          </td>
          <td valign="top" width="75%">
            <p>
              <a href="http://www.cs.toronto.edu/~henryzhou/movie4d/">
                <papertitle>Now You Shake Me: Towards Automatic 4D Cinema</papertitle>
              </a><br>
              <strong>Yuhao Zhou</strong>, Makarand Tapaswi, Sanja Fidler<br>
              <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <strong>(Spotlight)</strong> <br>
              <a id='movie4d_abstract', onclick="detail_switch(this.id)">Abstract</a> /
              <a id='movie4d_bib' onclick='detail_switch(this.id)'>Bibtex</a> /
              <a href='http://www.cs.toronto.edu/~henryzhou/movie4d/'>Project Web</a> /
              <a href='http://www.cs.toronto.edu/~henryzhou/movie4d/sources/cvpr2018.pdf'>PDF</a> /
              <a href="https://www.youtube.com/watch?v=O92bGCTxul8&feature=youtu.be&t=5550">CVPR Spotlight</a> /
              <a href="http://www.cs.toronto.edu/~henryzhou/movie4d/sources/movie4d_poster.pdf">Poster</a> 
              <br>
              Media:
              <a href="https://www.utoronto.ca/news/experience-what-characters-are-feeling-u-t-researchers-use-ai-add-4d-effects-movies"> UofT News</a> / 
              <a href="http://www.cbc.ca/listen/shows/here-and-now-toronto/segment/15555905">CBC Radio News</a> /
              <a href="https://www.inquisitr.com/4976832/ai-algorithm-turns-regular-movies-into-4d-motion-pictures/">Inquisitr News</a>
            </p>

            <p>
              <div id='movie4d_abstract_content' style='display:none;'>
                We are interested in enabling automatic 4D cinema by parsing physical and special effects from untrimmed movies. 
                These include effects such as physical interactions, water splashing, light, and shaking, and are grounded to either a character in the scene or the camera. 
                We collect a new dataset referred to as the Movie4D dataset which annotates over 9K effects in 63 movies. 
                We propose a Conditional Random Field model atop a neural network that brings together visual and audio information, as well as semantics in the form of person tracks. Our model further exploits correlations of effects between different characters in the clip as well as across movie threads. 
                We propose effect detection and classification as two tasks, and present results along with ablation studies on our dataset, paving the way towards 4D cinema in everyone&#39;s homes.
              </div>

              <div id='movie4d_bib_content' style="font-family:monospace;display:none;">
                @inproceedings{Zhou2017_Movie4D,</br>  
                author = {Yuhao Zhou and Makarand Tapaswi and Sanja Fidler},</br>  
                title = {{Now You Shake Me: Towards Automatic 4D Cinema}},</br>  
                year = {2018},</br>  
                booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},</br>  
                month = {Jun.},</br>  doi = {}</br>}
              </div>
            </p>

            
            
            <p></p>

          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td>
          <heading>Industry Experience</heading>
          <p>
            I spent most of my time as a software engineering intern in the first 3 summers during undergradate studies.
            Please email me for more details of the experience. <br>
          </p>
          </td>
        </tr>
        
      </table>
      
      <table width="100%" align="center" border="0" cellpadding="20">

        <tr>
          <td width="25%"><img src="images/industry/nv_logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              Nvidia Corporation <br> 
              Research Intern<br>
              Toronto, Canada <br>
              January, 2019 -  <br>
            </p>
            <p></p>
            <p>
              AI research team. <br>
              Under the supervison of Sanja Fidler, working on Computer Vision projects. <br>
            </p>
          </td>
        </tr>

        <tr>
          <td width="25%"><img src="images/industry/intel_logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              Intel PSG <br> 
              PEY (Professional Experience Year) Intern<br>
              San Jose, CA <br>
              May, 2017 - December, 2017 <br>
            </p>
            <p></p>
            <p>
              Participated in software development in Quartus high-level synthesis group. <br>
              Engaged in large-scale C++ programming projects on software backward compatibility. <br>
              Enhanced customers' usability to use pre-compiled products to compile on latest Quartus software. (Perl) <br>
            </p>
          </td>
        </tr>

        <tr>
          <td width="25%"><img src="images/industry/oracle_logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              Oracle Corp. <br> 
              R&#38;D Intern<br>
              Beijing, China <br>
              June, 2015 - Aug, 2015 <br>
            </p>
            <p></p>
            <p>
              Worked in R&#38;D department cloud computing group. <br>
              Exposure to cloud-computing architecture and networking. <br>
              Utilized integrated tools to manage cloud-computing resources and services for the entire R&#38;D department. <br>
            </p>
          </td>
        </tr>

        <tr>
          <td width="25%"><img src="images/industry/huawei_logo.png" alt="prl" width="160" ></td>
          <td width="75%" valign="top">
            <p>
              Huawei Technologies Co. Ltd <br> 
              Android Programming Intern<br>
              Beijing, China <br>
              May, 2015 - June, 2015 <br>
            </p>
            <p></p>
            <p>
              Beijing R&#38;D Deartment: automated testing team. <br>
              Familiarzed with Android OS and its GUI layout. <br>
              Transplanted old testing scripts (Java/Python) to allow automated testing on latest Ascend phone series. <br>
            </p>
          </td>
        </tr>

      </table>
      
      
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
          <td>
          <br>
          <p align="right">
            <font size="2">
            Template: <a href="https://github.com/jonbarron/jonbarron_website"><strong>This Guy</strong></a>
            </font>
          </p>
          </td>
      </tr>

      <tr>
        <td>
          <p align='center'>
            <img src="https://s04.flagcounter.com/mini/xnAl/bg_FFFFFF/txt_000000/border_FFFFFF/flags_0/" alt="Flag Counter" border="0">
          </p>
        </td>
      </tr>

      
      </table>


      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>

<script>
function detail_switch(click_id) {
    click_intro = click_id + '_content'
    var x = document.getElementById(click_intro);
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>

  </body>
</html>
